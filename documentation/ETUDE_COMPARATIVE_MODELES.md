# üìä √âTUDE COMPARATIVE DES MOD√àLES LLM - CHATBOT COOLLIBRI

## üìÖ Date de l'√©tude
Novembre 2025

---

## üéØ OBJECTIF DE L'√âTUDE

Comparer 4 mod√®les LLM diff√©rents pour d√©terminer le meilleur choix pour le chatbot CoolLibri en termes de :
- **Pr√©cision** : Fid√©lit√© aux donn√©es sources, absence d'hallucinations
- **Vitesse** : Temps de r√©ponse pour une exp√©rience utilisateur optimale
- **Style** : Qualit√© de r√©daction et ton professionnel
- **Compl√©tude** : Exhaustivit√© des r√©ponses

---

## ü§ñ LES 4 MOD√àLES √Ä COMPARER

### **Mod√®le 1 : llama3.1:8b** (R√âF√âRENCE ACTUELLE)
- **Taille** : 8 milliards de param√®tres
- **D√©veloppeur** : Meta AI
- **Date** : Juillet 2024
- **Avantages** : 
  - Tr√®s bon contexte (128k tokens)
  - Excellent pour r√©ponses d√©taill√©es
  - Bon √©quilibre qualit√©/performance
- **Inconv√©nients** :
  - Plus lent que les mod√®les 3B
  - Peut sur-d√©velopper les r√©ponses
- **RAM n√©cessaire** : ~5-6 GB

### **Mod√®le 2 : llama3.2:3b** (L√âGER ET RAPIDE)
- **Taille** : 3 milliards de param√®tres
- **D√©veloppeur** : Meta AI
- **Date** : Septembre 2024
- **Avantages** :
  - Plus rapide que 3.1:8b
  - Meilleur pour suivre instructions strictes
  - Moins tendance √† inventer
  - N√©cessite moins de RAM
- **Inconv√©nients** :
  - Contexte plus court (8k tokens vs 128k)
  - Peut √™tre moins d√©taill√©
- **RAM n√©cessaire** : ~2-3 GB

### **Mod√®le 3 : mistral:7b** (√âQUILIBRE FRAN√áAIS)
- **Taille** : 7 milliards de param√®tres
- **D√©veloppeur** : Mistral AI (entreprise fran√ßaise)
- **Date** : Septembre 2023 (r√©guli√®rement mis √† jour)
- **Avantages** :
  - Excellent en fran√ßais
  - Tr√®s bon √©quilibre vitesse/qualit√©
  - Reconnu pour pr√©cision factuelle
  - Bon pour service client
- **Inconv√©nients** :
  - Peut √™tre parfois verbeux
- **RAM n√©cessaire** : ~4-5 GB

### **Mod√®le 4 : phi3:medium** (PETIT MAIS PUISSANT)
- **Taille** : 14 milliards de param√®tres (architecture optimis√©e)
- **D√©veloppeur** : Microsoft
- **Date** : Avril 2024
- **Avantages** :
  - Tr√®s rapide malgr√© la taille
  - Excellent pour donn√©es structur√©es
  - Bon raisonnement
  - Performant en fran√ßais
- **Inconv√©nients** :
  - Peut √™tre trop concis
  - Moins connu que Llama/Mistral
- **RAM n√©cessaire** : ~8 GB

---

## üìù INSTALLATION DES MOD√àLES

### Commandes Ollama (dans PowerShell)

```powershell
# T√©l√©charger les mod√®les (√† ex√©cuter une seule fois)
ollama pull llama3.1:8b
ollama pull llama3.2:3b
ollama pull mistral:7b
ollama pull phi3:medium

# V√©rifier que tous les mod√®les sont install√©s
ollama list
```

---

## üéØ LES 3 CONFIGURATIONS √Ä TESTER PAR MOD√àLE

Pour chaque mod√®le, nous allons tester **3 configurations pertinentes** qui repr√©sentent des cas d'usage r√©alistes :

### **Configuration 1 : PR√âCISION MAXIMALE**
*Objectif : Fid√©lit√© absolue aux sources, z√©ro cr√©ativit√©*
- **Temperature** : 0.0 (aucune variation)
- **Top_P** : 0.3 (tr√®s conservateur)
- **Top_K** : 20 (vocabulaire restreint)
- **Num_Predict** : 800 (r√©ponses moyennes)
- **Top_K_Results** : 8 (contexte cibl√©)
- **Rerank_Top_N** : 4 (focus sur meilleur contenu)

**Cas d'usage** : Questions avec chiffres pr√©cis, donn√©es factuelles critiques

---

### **Configuration 2 : √âQUILIBR√âE (RECOMMAND√âE)**
*Objectif : Bon compromis pr√©cision/fluidit√©*
- **Temperature** : 0.15 (tr√®s l√©g√®re variation)
- **Top_P** : 0.5 (√©quilibr√©)
- **Top_K** : 40 (vocabulaire riche mais contr√¥l√©)
- **Num_Predict** : 900 (r√©ponses d√©taill√©es)
- **Top_K_Results** : 10 (bon contexte)
- **Rerank_Top_N** : 5 (√©quilibr√©)

**Cas d'usage** : Usage quotidien du chatbot, questions vari√©es

---

### **Configuration 3 : R√âPONSES COMPL√àTES**
*Objectif : R√©ponses d√©taill√©es et exhaustives*
- **Temperature** : 0.2 (l√©g√®re cr√©ativit√© pour formulations)
- **Top_P** : 0.6 (plus de diversit√©)
- **Top_K** : 50 (vocabulaire tr√®s riche)
- **Num_Predict** : 1200 (r√©ponses longues)
- **Top_K_Results** : 12 (maximum contexte)
- **Rerank_Top_N** : 6 (beaucoup de sources)

**Cas d'usage** : Questions complexes n√©cessitant explications d√©taill√©es

---

## ‚öôÔ∏è PARAM√àTRES √Ä MODIFIER ET LEUR LOCALISATION

### üîµ PARAM√àTRE 1 : MOD√àLE LLM

**üìÅ Fichier** : `backend/app/core/config.py`  
**üìç Ligne** : ~20

```python
class Settings(BaseSettings):
    # LLM Configuration
    ollama_base_url: str = "http://localhost:11434"
    ollama_model: str = "llama3.1:8b"  # ‚Üê MODIFIER ICI
```

**üéØ Comment modifier :**
Remplacez `"llama3.1:8b"` par l'un des mod√®les suivants :
- `"llama3.2:3b"`
- `"mistral:7b"`
- `"phi3:medium"`

**üìå Exemple :**
```python
ollama_model: str = "mistral:7b"  # Test avec Mistral
```

**üí° R√¥le** : D√©finit quel mod√®le Ollama utilise pour g√©n√©rer les r√©ponses. C'est le param√®tre principal √† changer pour comparer les mod√®les.

---

### üîµ PARAM√àTRE 2 : TEMPERATURE

**üìÅ Fichier** : `backend/app/services/llm.py`  
**üìç Ligne** : ~78 (fonction `generate_response`)

```python
options={
    "temperature": 0.1,  # ‚Üê MODIFIER ICI
    "top_p": 0.5,
    "top_k": 40,
    "num_predict": 900,
    "repeat_penalty": 1.2,
}
```

**üéØ Valeurs √† tester :**
- `0.0` - Maximum pr√©cision, z√©ro cr√©ativit√© (r√©p√©titif)
- `0.1` - Tr√®s pr√©cis, fid√®le aux sources (ACTUEL)
- `0.3` - √âquilibr√© pr√©cision/vari√©t√©
- `0.5` - Plus de vari√©t√© dans les formulations
- `0.7` - Cr√©atif mais peut d√©vier

**üí° R√¥le** : Contr√¥le la "cr√©ativit√©" du mod√®le. 
- **Basse (0.0-0.2)** : Le mod√®le choisit toujours les mots les plus probables ‚Üí r√©ponses tr√®s pr√©visibles et pr√©cises
- **Moyenne (0.3-0.5)** : Un peu de variation dans les formulations
- **Haute (0.6-1.0)** : Beaucoup de cr√©ativit√© ‚Üí risque d'inventer des choses

**üéØ Recommandation pour chatbot service client** : 0.0 √† 0.2 (pr√©cision maximale)

---

### üîµ PARAM√àTRE 3 : TOP_P (Nucleus Sampling)

**üìÅ Fichier** : `backend/app/services/llm.py`  
**üìç Ligne** : ~78

```python
options={
    "temperature": 0.1,
    "top_p": 0.5,  # ‚Üê MODIFIER ICI
    "top_k": 40,
    "num_predict": 900,
    "repeat_penalty": 1.2,
}
```

**üéØ Valeurs √† tester :**
- `0.1` - Tr√®s conservateur
- `0.3` - Conservateur
- `0.5` - √âquilibr√© (ACTUEL)
- `0.7` - Plus de diversit√©
- `0.9` - Maximum diversit√©

**üí° R√¥le** : Contr√¥le la diversit√© en limitant le pool de mots consid√©r√©s.
- **Principe** : Le mod√®le ne consid√®re que les mots dont la probabilit√© cumul√©e atteint `top_p`
- **0.1** : Seulement les 10% de mots les plus probables ‚Üí tr√®s pr√©visible
- **0.5** : Les 50% de mots les plus probables ‚Üí √©quilibr√©
- **0.9** : Les 90% de mots les plus probables ‚Üí tr√®s vari√©

**üéØ Recommandation** : 0.3 √† 0.5 pour service client (balance diversit√©/pr√©cision)

---

### üîµ PARAM√àTRE 4 : TOP_K

**üìÅ Fichier** : `backend/app/services/llm.py`  
**üìç Ligne** : ~78

```python
options={
    "temperature": 0.1,
    "top_p": 0.5,
    "top_k": 40,  # ‚Üê MODIFIER ICI
    "num_predict": 900,
    "repeat_penalty": 1.2,
}
```

**üéØ Valeurs √† tester :**
- `10` - Tr√®s limit√© (vocabulaire restreint)
- `20` - Conservateur
- `40` - √âquilibr√© (ACTUEL)
- `80` - Vocabulaire riche
- `100` - Maximum diversit√© vocabulaire

**üí° R√¥le** : Limite le nombre de mots candidats √† chaque g√©n√©ration.
- **Principe** : √Ä chaque mot, le mod√®le ne consid√®re que les K mots les plus probables
- **10** : Seulement les 10 mots les plus probables ‚Üí style r√©p√©titif
- **40** : Les 40 mots les plus probables ‚Üí bon √©quilibre
- **100** : Les 100 mots les plus probables ‚Üí vocabulaire tr√®s vari√©

**üéØ Recommandation** : 30 √† 50 pour service client (vocabulaire professionnel mais pas r√©p√©titif)

---

### üîµ PARAM√àTRE 5 : NUM_PREDICT (Longueur de r√©ponse)

**üìÅ Fichier** : `backend/app/services/llm.py`  
**üìç Ligne** : ~78

```python
options={
    "temperature": 0.1,
    "top_p": 0.5,
    "top_k": 40,
    "num_predict": 900,  # ‚Üê MODIFIER ICI
    "repeat_penalty": 1.2,
}
```

**üéØ Valeurs √† tester :**
- `400` - R√©ponses courtes/concises
- `600` - R√©ponses moyennes
- `900` - R√©ponses d√©taill√©es (ACTUEL)
- `1200` - R√©ponses tr√®s compl√®tes
- `1500` - R√©ponses exhaustives

**üí° R√¥le** : Limite maximale de tokens (mots) dans la r√©ponse.
- **Principe** : D√©finit le nombre maximum de "tokens" (morceaux de mots) que le mod√®le peut g√©n√©rer
- **400 tokens** : ~300 mots ‚Üí r√©ponses concises
- **900 tokens** : ~650 mots ‚Üí r√©ponses d√©taill√©es
- **1500 tokens** : ~1100 mots ‚Üí r√©ponses tr√®s compl√®tes

**‚ö†Ô∏è Impact** : 
- Plus √©lev√© = r√©ponses plus compl√®tes MAIS plus lentes
- Plus bas = r√©ponses rapides MAIS risque de coupure

**üéØ Recommandation** : 600 √† 1000 selon type de questions

---

### üîµ PARAM√àTRE 6 : TOP_K_RESULTS (RAG - Nombre de documents r√©cup√©r√©s)

**üìÅ Fichier** : `backend/app/core/config.py`  
**üìç Ligne** : ~27

```python
class Settings(BaseSettings):
    # RAG Configuration
    chunk_size: int = 1000
    chunk_overlap: int = 300
    top_k_results: int = 10  # ‚Üê MODIFIER ICI
    rerank_top_n: int = 5
```

**üéØ Valeurs √† tester :**
- `5` - Peu de contexte (rapide mais risque d'incomplet)
- `10` - Bon √©quilibre (ACTUEL)
- `15` - Beaucoup de contexte (plus lent mais plus complet)
- `20` - Maximum contexte (tr√®s lent)

**üí° R√¥le** : Nombre de chunks de documents r√©cup√©r√©s de la base vectorielle.
- **Principe** : Avant de g√©n√©rer la r√©ponse, le syst√®me cherche les K documents les plus pertinents
- **5 documents** : Rapide mais peut manquer d'info
- **10 documents** : Bon √©quilibre
- **20 documents** : Beaucoup de contexte mais peut noyer l'info importante

**‚ö†Ô∏è Impact** : 
- Plus √©lev√© = plus de contexte pour le LLM MAIS plus lent et risque de confusion
- Plus bas = plus rapide MAIS risque de manquer des infos

**üéØ Recommandation** : 8 √† 12 pour √©quilibre vitesse/qualit√©

---

### üîµ PARAM√àTRE 7 : RERANK_TOP_N (RAG - Nombre de documents finaux)

**üìÅ Fichier** : `backend/app/core/config.py`  
**üìç Ligne** : ~27

```python
class Settings(BaseSettings):
    # RAG Configuration
    chunk_size: int = 1000
    chunk_overlap: int = 300
    top_k_results: int = 10
    rerank_top_n: int = 5  # ‚Üê MODIFIER ICI
```

**üéØ Valeurs √† tester :**
- `3` - Contexte minimal (tr√®s cibl√©)
- `5` - √âquilibr√© (ACTUEL)
- `7` - Plus de contexte
- `10` - Maximum contexte (doit √™tre ‚â§ top_k_results)

**üí° R√¥le** : Apr√®s r√©cup√©ration de `top_k_results` documents, re-classe et garde seulement les N meilleurs.
- **Principe** : 
  1. R√©cup√®re `top_k_results` documents (ex: 10)
  2. Re-classe ces 10 avec un algorithme plus pr√©cis
  3. Garde seulement les `rerank_top_n` meilleurs (ex: 5)
- **3 documents** : Contexte tr√®s cibl√©, r√©ponses pr√©cises
- **5 documents** : Bon √©quilibre
- **10 documents** : Beaucoup de contexte, peut diluer l'info

**‚ö†Ô∏è R√®gle** : `rerank_top_n` doit TOUJOURS √™tre ‚â§ `top_k_results`

**üéØ Recommandation** : 4 √† 6 pour pr√©cision optimale

---

## üé® CONFIGURATION RECOMMAND√âE PAR TYPE DE QUESTION

### Pour questions simples/directes
```python
temperature: 0.1
top_p: 0.3
top_k: 30
num_predict: 400
top_k_results: 8
rerank_top_n: 3
```

### Pour questions complexes/d√©taill√©es
```python
temperature: 0.2
top_p: 0.5
top_k: 40
num_predict: 1000
top_k_results: 12
rerank_top_n: 6
```

### Pour questions avec chiffres (MAXIMUM PR√âCISION)
```python
temperature: 0.0
top_p: 0.3
top_k: 20
num_predict: 600
top_k_results: 10
rerank_top_n: 5
```

---

## üìã LES 30 QUESTIONS DE TEST

### üü¢ CAT√âGORIE 1 : QUESTIONS FACILES/DIRECTES (6 questions)

**Q1** : Quels sont les types de reliure disponibles chez CoolLibri ?  
**R√©ponse attendue** : 4 types (Dos Carr√© Coll√©, Rembord√©, Agraf√©, Spirale)

**Q2** : Quel est le nombre minimum de pages pour la reliure agraf√©e ?  
**R√©ponse attendue** : 8 pages minimum

**Q3** : Quel est le nombre maximum de pages pour la reliure agraf√©e ?  
**R√©ponse attendue** : 60 pages maximum

**Q4** : Quelle contrainte technique existe pour la reliure agraf√©e ?  
**R√©ponse attendue** : Le nombre de pages doit √™tre un multiple de 4

**Q5** : Quelle est la couverture utilis√©e pour le Dos Carr√© Coll√© ?  
**R√©ponse attendue** : Couverture souple, papier couch√© 300g

**Q6** : Quel type de reliure permet une ouverture √† 360 degr√©s ?  
**R√©ponse attendue** : Spirale

---

### üü° CAT√âGORIE 2 : QUESTIONS AVEC CHIFFRES PR√âCIS (8 questions)

**Q7** : Donne-moi le nombre minimum de pages pour la reliure Dos Carr√© Coll√© selon le type de papier.  
**R√©ponse attendue** : 
- Papier 60g : 60 pages minimum
- Papier 80g : 80 pages minimum
- Papier 90g satin√© : 90 pages minimum

**Q8** : Donne-moi le nombre maximum de pages pour la reliure Dos Carr√© Coll√© selon le type de papier.  
**R√©ponse attendue** :
- Papier 60g : 700 pages maximum
- Papier 80g : 500 pages maximum
- Papier 90g satin√© : 500 pages maximum

**Q9** : Quelles sont les limites de pages pour la reliure Rembord√© ?  
**R√©ponse attendue** : Minimum 24 pages, maximum 100 √† 150 pages selon l'√©paisseur du papier

**Q10** : Quelles sont les limites de pages pour la reliure Spirale ?  
**R√©ponse attendue** : Minimum 1 page, maximum 290 √† 500 pages selon l'√©paisseur du papier

**Q11** : Donne-moi le minimum et le maximum de pages en fonction de chaque reliure.  
**R√©ponse attendue** : 
- Dos Carr√© Coll√© : 60-90 pages min, 500-700 pages max
- Rembord√© : 24 pages min, 100-150 pages max
- Agraf√© : 8 pages min, 60 pages max
- Spirale : 1 page min, 290-500 pages max

**Q12** : Si j'ai un livre de 85 pages en papier 80g, puis-je utiliser le Dos Carr√© Coll√© ?  
**R√©ponse attendue** : Oui (85 pages ‚â• 80 pages minimum pour papier 80g)

**Q13** : Si j'ai un livre de 650 pages en papier 80g, puis-je utiliser le Dos Carr√© Coll√© ?  
**R√©ponse attendue** : Non (650 pages > 500 pages maximum pour papier 80g). Solution : utiliser papier 60g ou s√©parer en tomes.

**Q14** : Si j'ai 75 pages, puis-je utiliser la reliure agraf√©e ?  
**R√©ponse attendue** : Non (75 > 60 pages max ET 75 n'est pas un multiple de 4)

---

### üîµ CAT√âGORIE 3 : QUESTIONS COMPARATIVES (6 questions)

**Q15** : Quelle est la diff√©rence entre Dos Carr√© Coll√© et Rembord√© ?  
**R√©ponse attendue** : Dos Carr√© Coll√© = couverture souple ; Rembord√© = couverture rigide

**Q16** : Quelle reliure choisir pour un roman de 250 pages ?  
**R√©ponse attendue** : Dos Carr√© Coll√© ou Spirale (Rembord√© limit√© √† 150 pages max)

**Q17** : Quelle est la reliure la plus √©conomique ?  
**R√©ponse attendue** : Agraf√© (mais limit√© √† 60 pages max)

**Q18** : Quelle reliure offre la meilleure protection ?  
**R√©ponse attendue** : Rembord√© (couverture rigide)

**Q19** : Quelle reliure est id√©ale pour consulter fr√©quemment un document ?  
**R√©ponse attendue** : Spirale (ouverture √† 360¬∞, pages √† plat)

**Q20** : Quelle reliure est utilis√©e pour les livres vendus en librairie ?  
**R√©ponse attendue** : Dos Carr√© Coll√© (finition identique aux livres de librairie)

---

### üü† CAT√âGORIE 4 : QUESTIONS COMPLEXES/MULTI-√âTAPES (6 questions)

**Q21** : Je veux imprimer une bande dessin√©e de 120 pages. Quelle reliure me recommandes-tu et pourquoi ?  
**R√©ponse attendue** : 
- Rembord√© si possible (mais limite 100-150 pages selon papier, donc v√©rifier √©paisseur)
- Sinon Dos Carr√© Coll√© (bonne alternative, 120 pages OK)
- Expliquer avantages/inconv√©nients

**Q22** : Mon livre fait 600 pages en papier 90g. Quelles sont mes options ?  
**R√©ponse attendue** :
- Papier 90g max = 500 pages ‚Üí impossible
- Solutions : 
  1. Passer au papier 60g (max 700 pages)
  2. S√©parer en 2 tomes
  3. Utiliser Spirale si acceptable

**Q23** : Je veux imprimer 40 pages. Quelles reliures sont possibles et laquelle recommandes-tu ?  
**R√©ponse attendue** :
- Agraf√© : OUI (40 est multiple de 4 et entre 8-60)
- Spirale : OUI (min 1 page)
- Dos Carr√© Coll√© : NON (40 < 60 pages min)
- Rembord√© : OUI (40 > 24 min et < 150 max)
- Recommandation : Agraf√© (√©conomique) ou Rembord√© (qualit√©)

**Q24** : Quel format et quelle reliure pour un livre de recettes de 180 pages ?  
**R√©ponse attendue** :
- Reliure : Spirale (ouverture √† plat, id√©al cuisine)
- Format : A4 Portrait ou A5
- Papier : 90g satin√© (r√©siste aux taches)

**Q25** : Je veux faire un livre photo premium de 80 pages. Configuration compl√®te ?  
**R√©ponse attendue** :
- Reliure : Rembord√© (protection maximale, luxueux)
- Format : A4 Paysage ou A5 Paysage
- Papier : Papier photo couch√© haute qualit√©

**Q26** : J'ai un magazine de 32 pages √† imprimer en 500 exemplaires. Quelle solution et pourquoi ?  
**R√©ponse attendue** :
- Reliure : Agraf√© (32 est multiple de 4, √©conomique pour gros tirage)
- Format : A4 Portrait ou A5
- Papier : 80g ou couch√© selon rendu
- Avantages : Rapide, √©conomique pour 500 ex

---

### üî¥ CAT√âGORIE 5 : QUESTIONS PI√àGES/CHALLENGEANTES (4 questions)

**Q27** : Puis-je imprimer 1000 pages en Spirale ?  
**R√©ponse attendue** : Non (max 290-500 pages selon papier)

**Q28** : Puis-je imprimer 50 pages en Dos Carr√© Coll√© ?  
**R√©ponse attendue** : Non (minimum 60-90 pages selon papier)

**Q29** : Est-ce que toutes les reliures acceptent le papier 60g ?  
**R√©ponse attendue** : Information non pr√©cis√©e dans les sources. Recommander de contacter CoolLibri pour confirmation.

**Q30** : Quelle est la diff√©rence de prix entre Agraf√© et Rembord√© pour 50 pages ?  
**R√©ponse attendue** : Information tarifaire non disponible dans la base de connaissances. Recommander de demander un devis √† CoolLibri.

---

## üìä CRIT√àRES D'√âVALUATION (Grille de notation /100)

### 1. PR√âCISION DES CHIFFRES (/40 points)

**Chiffres exacts** (/10)
- 10 pts : Tous les chiffres sont EXACTEMENT corrects (copi√©s des sources)
- 7 pts : 1 chiffre approxim√© (ex: "environ 60" au lieu de "60")
- 4 pts : 2-3 chiffres approxim√©s
- 0 pt : Chiffres invent√©s ou multiples erreurs

**Absence d'hallucination** (/10)
- 10 pts : Aucune invention, tout est bas√© sur les sources
- 7 pts : 1 d√©tail invent√© mineur
- 4 pts : Plusieurs d√©tails invent√©s
- 0 pt : Informations compl√®tement fausses

**Compl√©tude des donn√©es** (/10)
- 10 pts : Tous les d√©tails pertinents donn√©s (min, max, types de papier)
- 7 pts : 1 d√©tail manquant
- 4 pts : Plusieurs d√©tails manquants
- 0 pt : R√©ponse incompl√®te

**Coh√©rence** (/10)
- 10 pts : R√©ponse logique et coh√©rente du d√©but √† la fin
- 7 pts : 1 petite incoh√©rence
- 4 pts : Plusieurs incoh√©rences
- 0 pt : R√©ponse contradictoire

---

### 2. VITESSE DE R√âPONSE (/20 points)

- **20 pts** : < 2 secondes (excellent)
- **15 pts** : 2-4 secondes (tr√®s bien)
- **10 pts** : 4-6 secondes (bien)
- **5 pts** : 6-8 secondes (acceptable)
- **0 pt** : > 8 secondes (trop lent)

**Note** : Le timer sera affich√© automatiquement dans le frontend

---

### 3. QUALIT√â DU STYLE (/20 points)

**Ton professionnel** (/5)
- 5 pts : Ton chaleureux, professionnel et rassurant
- 3 pts : Ton correct mais un peu froid ou trop familier
- 1 pt : Ton inappropri√©
- 0 pt : Ton non professionnel

**Structure claire** (/5)
- 5 pts : Paragraphes bien organis√©s, listes √† puces si pertinent
- 3 pts : Structure correcte mais am√©liorable
- 1 pt : Structure confuse
- 0 pt : Pas de structure

**Authenticit√©** (/5)
- 5 pts : Parle avec confiance, JAMAIS "selon le document"
- 3 pts : 1 mention de source ("selon nos documents")
- 1 pt : Plusieurs mentions de sources
- 0 pt : Constamment r√©f√®re aux documents

**Adaptation au contexte** (/5)
- 5 pts : R√©ponse parfaitement adapt√©e au niveau de la question
- 3 pts : R√©ponse adapt√©e mais perfectible
- 1 pt : R√©ponse trop technique ou trop simple
- 0 pt : R√©ponse inadapt√©e

---

### 4. COMPL√âTUDE DE LA R√âPONSE (/20 points)

**R√©pond √† toute la question** (/10)
- 10 pts : R√©pond √† TOUS les aspects de la question
- 7 pts : R√©pond √† la majorit√© mais oublie 1 aspect
- 4 pts : R√©pond partiellement
- 0 pt : Ne r√©pond pas √† la question

**D√©tails pertinents** (/10)
- 10 pts : Donne tous les d√©tails utiles sans superflu
- 7 pts : Manque 1-2 d√©tails utiles
- 4 pts : Manque plusieurs d√©tails importants
- 0 pt : R√©ponse trop vague

---

## üìà TABLEAU DE SYNTH√àSE

Pour chaque test, remplissez :

| Crit√®re | Points | Notes |
|---------|--------|-------|
| **PR√âCISION** | /40 | |
| - Chiffres exacts | /10 | |
| - Absence hallucination | /10 | |
| - Compl√©tude donn√©es | /10 | |
| - Coh√©rence | /10 | |
| **VITESSE** | /20 | |
| - Temps de r√©ponse | /20 | Timer affich√© |
| **STYLE** | /20 | |
| - Ton professionnel | /5 | |
| - Structure claire | /5 | |
| - Authenticit√© | /5 | |
| - Adaptation contexte | /5 | |
| **COMPL√âTUDE** | /20 | |
| - R√©pond √† tout | /10 | |
| - D√©tails pertinents | /10 | |
| **TOTAL** | **/100** | |

---

## üîÑ PROC√âDURE DE TEST SIMPLIFI√âE

### √âtape 1 : Pr√©parer l'environnement
1. T√©l√©charger les 4 mod√®les avec Ollama :
```powershell
ollama pull llama3.1:8b
ollama pull llama3.2:3b
ollama pull mistral:7b
ollama pull phi3:medium
```

2. Ouvrir le template Google Sheets
3. Dupliquer l'onglet pour chaque combinaison mod√®le + configuration

### √âtape 2 : Pour chaque mod√®le (4 mod√®les √ó 3 configs = 12 tests)

**2.1. Configurer le mod√®le et les param√®tres**

Modifier **`backend/app/core/config.py`** (ligne ~20-27) :
```python
class Settings(BaseSettings):
    # LLM Configuration
    ollama_base_url: str = "http://localhost:11434"
    ollama_model: str = "llama3.1:8b"  # ‚Üê CHANGER LE MOD√àLE ICI
    
    # RAG Configuration
    chunk_size: int = 1000
    chunk_overlap: int = 300
    top_k_results: int = 10  # ‚Üê CHANGER SELON CONFIG
    rerank_top_n: int = 5    # ‚Üê CHANGER SELON CONFIG
```

Modifier **`backend/app/services/llm.py`** (ligne ~78) :
```python
options={
    "temperature": 0.15,     # ‚Üê CHANGER SELON CONFIG
    "top_p": 0.5,           # ‚Üê CHANGER SELON CONFIG
    "top_k": 40,            # ‚Üê CHANGER SELON CONFIG
    "num_predict": 900,     # ‚Üê CHANGER SELON CONFIG
    "repeat_penalty": 1.2,
}
```

**2.2. Red√©marrer le backend**
```powershell
cd backend
.\.venv\Scripts\Activate.ps1
uvicorn main:app --reload --host 0.0.0.0 --port 8080
```

**2.3. Tester les 30 questions**
- Poser chaque question
- Le **timer s'affiche automatiquement** sous la r√©ponse
- Noter le **temps** dans Google Sheets
- √âvaluer la **qualit√©** de 0 √† 10
- Ajouter observations si n√©cessaire

**2.4. Passer √† la configuration suivante**
- Modifier les param√®tres
- Red√©marrer le backend
- Recommencer les 30 questions

### √âtape 3 : Analyser les r√©sultats
- Comparer scores moyens par mod√®le
- Comparer scores par configuration
- Identifier le meilleur combo mod√®le + configuration
- Analyser par cat√©gorie de questions

---

## üìä CRIT√àRES D'√âVALUATION SIMPLIFI√âS

### 1. VITESSE (temps brut)
- Notez simplement le temps affich√© (ex: 2.45s)
- Google Sheets calculera automatiquement la moyenne

### 2. QUALIT√â GLOBALE (/10 points)
√âvaluez globalement la r√©ponse en tenant compte de :
- ‚úÖ **Pr√©cision** : Chiffres exacts ? Pas d'invention ?
- ‚úÖ **Compl√©tude** : R√©pond √† toute la question ?
- ‚úÖ **Clart√©** : Bien structur√© ? Facile √† comprendre ?
- ‚úÖ **Style** : Ton professionnel ? Pas de mention de sources ?
- ‚úÖ **Pertinence** : Adapt√© √† la question ?

**Bar√®me simplifi√© :**
- **9-10** : Excellente r√©ponse, aucun d√©faut
- **7-8** : Tr√®s bonne r√©ponse, 1-2 petits d√©fauts
- **5-6** : Bonne r√©ponse, quelques manques
- **3-4** : R√©ponse moyenne, plusieurs probl√®mes
- **0-2** : Mauvaise r√©ponse, erreurs majeures

---

## üìà ANALYSE DES R√âSULTATS

### Tableau de synth√®se (√† cr√©er dans Google Sheets)

| Mod√®le | Config | Vitesse Moy. | Qualit√© Moy. | Score Pond√©r√©* |
|--------|--------|--------------|--------------|----------------|
| llama3.1:8b | Pr√©cision Max | | | |
| llama3.1:8b | √âquilibr√©e | | | |
| llama3.1:8b | Compl√®te | | | |
| llama3.2:3b | Pr√©cision Max | | | |
| llama3.2:3b | √âquilibr√©e | | | |
| llama3.2:3b | Compl√®te | | | |
| mistral:7b | Pr√©cision Max | | | |
| mistral:7b | √âquilibr√©e | | | |
| mistral:7b | Compl√®te | | | |
| phi3:medium | Pr√©cision Max | | | |
| phi3:medium | √âquilibr√©e | | | |
| phi3:medium | Compl√®te | | | |

*Score Pond√©r√© = (Qualit√© √ó 0.7) + (Bonus Vitesse √ó 0.3)
- Bonus Vitesse : 10 pts si < 2s, 8 pts si 2-4s, 6 pts si 4-6s, etc.

---

## üìä PR√âSENTATION AU MANAGER (Structure simplifi√©e)

### 1. CONTEXTE
- Probl√®me : Inconsistances et lenteur du chatbot
- Objectif : Trouver le meilleur mod√®le + configuration

### 2. M√âTHODOLOGIE
- **4 mod√®les** test√©s (llama3.1:8b, llama3.2:3b, mistral:7b, phi3:medium)
- **3 configurations** par mod√®le (Pr√©cision Max, √âquilibr√©e, Compl√®te)
- **30 questions** par test (150 questions factuelles, comparatives, complexes)
- **2 crit√®res** : Vitesse de r√©ponse + Qualit√© globale (/10)

### 3. R√âSULTATS
- **Graphique 1** : Qualit√© moyenne par mod√®le (barres)
- **Graphique 2** : Vitesse moyenne par mod√®le (barres)
- **Graphique 3** : Score pond√©r√© par combinaison (tableau de chaleur)
- **Tableau** : Top 3 meilleures configurations

### 4. RECOMMANDATION
- **Mod√®le recommand√©** : [√Ä remplir]
- **Configuration recommand√©e** : [√Ä remplir]
- **B√©n√©fices attendus** :
  - Am√©lioration pr√©cision : +X%
  - Am√©lioration vitesse : -X secondes
  - Consistance des r√©ponses : Excellent

### 5. PLAN DE D√âPLOIEMENT
1. Tests finaux sur √©chantillon utilisateurs r√©els
2. Migration progressive (A/B testing)
3. Monitoring post-d√©ploiement (1 semaine)
4. Ajustements fins si n√©cessaire

---

## üìù NOTES IMPORTANTES

### ‚ö†Ô∏è √Ä faire avant chaque test
1. Vider le cache du navigateur (Ctrl+Shift+Delete)
2. Red√©marrer le backend apr√®s chaque changement de config
3. Attendre 10 secondes que le mod√®le charge

### ‚ö†Ô∏è Bonnes pratiques
- Tester chaque question 2 fois pour v√©rifier consistance
- Noter toute observation qualitative (style, formulation)
- Comparer r√©ponses similaires entre mod√®les

### ‚ö†Ô∏è Pi√®ges √† √©viter
- Ne pas changer plusieurs param√®tres √† la fois
- Ne pas tester avec cache navigateur plein
- Ne pas comparer r√©sultats avec backend pas red√©marr√©

---

**Bonne √©tude comparative ! üöÄ**
